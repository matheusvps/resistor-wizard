{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d544c87-9967-4b98-8fb5-0aa388f36beb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c88fb99c",
   "metadata": {},
   "source": [
    "##### *This file needs to be placed on ../Backend/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83425b-8b41-4b69-8277-18192a8138f0",
   "metadata": {},
   "source": [
    "### Imports packages needed and defines GLOBAL variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80fdf00f-c5e1-4706-a51d-5a961b7e45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "CROP_AMOUNT = 3\n",
    "tmp_dir = os.path.join(os.getcwd(),\"tmp\")\n",
    "tmp_crop = os.path.join(tmp_dir, \"crop.png\")\n",
    "tmp_mask = os.path.join(tmp_dir, \"mask.png\")\n",
    "if not os.path.isdir(tmp_dir):\n",
    "    os.makedirs(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8933d334-1c13-461e-aa2f-9227f63c5a43",
   "metadata": {},
   "source": [
    "### Loads pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abd17fc-2b2f-4ccc-9f2c-b90594fc272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropResistor = YOLO(\"YOLO_Cropper\\\\latest\\\\best.pt\")\n",
    "findColorBands = YOLO(\"YOLO_Segmenter\\\\latest\\\\best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386edf3-1809-4a5c-82ce-5818254bbed1",
   "metadata": {},
   "source": [
    "### Functions used for handling inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5f075d-2f69-4ce0-a685-fdaa34a42ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crops a numpy array image using a bounding box\n",
    "def cropImage(image, box):\n",
    "    return image[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n",
    "\n",
    "# Checks if two colors are equal\n",
    "def eqq(a,b):\n",
    "    if len(a) != len(b):\n",
    "        return False\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Class mask for grouping objects\n",
    "class Mask:\n",
    "    def __init__(self, img, bbox=[], contour=[]):\n",
    "        self.image = img\n",
    "        self.orig_shape = img.shape\n",
    "        self.mask = np.zeros_like(img, dtype=np.uint8)  # creates mask of same size as original image\n",
    "        self.size = -1  # Number of non-zero pixels\n",
    "        self.avgColor = (None, None, None)\n",
    "        self.bbox = bbox\n",
    "        self.contour = contour\n",
    "        self.index = -1  # This color's position relative to others\n",
    "        self.color = \"\"  # A string identifier of the color the mask represents\n",
    "    # Bitwise AND on the original image using the mask\n",
    "    def maskImage(self, crop=1):\n",
    "        pixels = np.zeros_like(self.image, dtype=np.uint8)\n",
    "        for x in range(len(self.image)):\n",
    "            for y in range(len(self.image[0])):\n",
    "                if eqq(self.mask[x][y], [255,255,255]):\n",
    "                    if x-crop >= 0 and x+crop < len(self.image) and y-crop >= 0 and y+crop < len(self.image[0]):\n",
    "                        if eqq(self.mask[x-crop][y], [255,255,255]) and eqq(self.mask[x+crop][y], [255,255,255]) and eqq(self.mask[x][y-crop], [255,255,255]) and eqq(self.mask[x][y+crop], [255,255,255]):\n",
    "                            pixels[x][y] = self.image[x][y]\n",
    "                        else:\n",
    "                            self.size -= 1\n",
    "        return pixels\n",
    "    # Calculates average color on the color band associated with the mask\n",
    "    def sample_avg_color(self):\n",
    "        pixels = self.maskImage(crop=CROP_AMOUNT)\n",
    "        self.avgColor = np.sum(pixels.reshape((-1,1,3)), axis=0) / self.size   \n",
    "    # Checks if a point is inside the mask's bounding box\n",
    "    def contains(self, point):\n",
    "        if list(point) < self.bbox[0:2].tolist() or list(point) > self.bbox[2:4].tolist():\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "# Calculates the centroid of a rectangle\n",
    "def get_centroid(vertex):\n",
    "    cX = (vertex[2] + vertex[0])/2\n",
    "    cY = (vertex[3] + vertex[1])/2\n",
    "    return (cX, cY)\n",
    "\n",
    "# Calculates the linear regression of the points in a 2D dataset: Y in function of X (Y= a*X + b)\n",
    "def lin_reg(data):\n",
    "    X = np.array([i[0] for i in data])\n",
    "    Y = np.array([i[1] for i in data])\n",
    "    a = ((len(data) * np.sum(X*Y)) - (np.sum(X) * np.sum(Y)))/(len(data) * np.sum(X*X) - (np.sum(X))**2)\n",
    "    b = ((np.sum(Y) * np.sum(X*X)) - (np.sum(X) * np.sum(X*Y)))/(len(data) * np.sum(X*X) - (np.sum(X))**2)\n",
    "    return a,b\n",
    "\n",
    "# Converts BGR color to HSV (0-360, 0-255, 0-255)\n",
    "def cvtBGR2HSV(bgr, paint=False):\n",
    "    B,G,R = bgr\n",
    "    Rp = R/255 \n",
    "    Gp = G/255 \n",
    "    Bp = B/255\n",
    "    Cmax = max(Rp, Gp, Bp)\n",
    "    Cmin = min(Rp, Gp, Bp)\n",
    "    delta = Cmax - Cmin\n",
    "    #\n",
    "    if delta == 0:\n",
    "        H = 0\n",
    "    elif Cmax == Rp:\n",
    "        H = 60 * (((Gp - Bp) / delta) % 6)\n",
    "    elif Cmax == Gp:\n",
    "        H = 60 * (((Bp - Rp) / delta) + 2)\n",
    "    elif Cmax == Bp:\n",
    "        H = 60 * (((Rp - Gp) / delta) + 4)\n",
    "    #\n",
    "    if Cmax == 0:\n",
    "        S = 0\n",
    "    else:\n",
    "        S = delta/Cmax\n",
    "    #\n",
    "    V = Cmax\n",
    "\n",
    "    if paint:\n",
    "        S *= 100\n",
    "        V *= 100\n",
    "    else:\n",
    "        S *= 255\n",
    "        V *= 255\n",
    "    return [int(i) for i in (H,S,V)]\n",
    "    \n",
    "\n",
    "# Retrieves the pixels contained in the contours given by the model prediction\n",
    "def get_segmentation_masks(img, inference, data=255):\n",
    "    image = cv.imread(img)\n",
    "    masks = [Mask(image) for i in range(len(inference[0].masks.xy))]\n",
    "    #\n",
    "    for i in range(len(inference[0].masks.xy)):\n",
    "        polygon = inference[0].masks.xy[i].astype(int)\n",
    "        masks[i].bbox = inference[0].boxes.cpu().data[i]\n",
    "        masks[i].contour = polygon.reshape((-1, 1, 2))  # Reshape to match the format expected by cv.drawContours\n",
    "        masks[i].mask = cv.fillPoly(masks[i].mask, [masks[i].contour], (data, data, data)) # converts polygon points to pixels inside it\n",
    "        masks[i].size = 0\n",
    "        for j in masks[i].mask.reshape((-1,1,3)):\n",
    "            if not eqq(j[0], [0,0,0]):\n",
    "                masks[i].size += 1\n",
    "        masks[i].sample_avg_color()\n",
    "    return masks\n",
    "\n",
    "# Finds the mask that contains a given point – considers a point can belong to a single mask\n",
    "def retrieve_point_in_mask(masks, point):\n",
    "    for mask in masks:\n",
    "        if mask.contains(point):\n",
    "            return mask\n",
    "\n",
    "# Calculates the possible orders of the color bands – assumes the bands are approximately\n",
    "#     linear, which is reasonable given that resistors follow this standard\n",
    "def order_masks(masks, inference):\n",
    "    boxes = inference[0].boxes.cpu().data\n",
    "    vertex = [v[:4] for v in boxes]\n",
    "    centroids = [get_centroid(v) for v in vertex]\n",
    "    #\n",
    "    # Calculates the line that approximately crosses the centroids – it's used to find the order in which the bands are disposed\n",
    "    parameters = lin_reg(centroids)\n",
    "    lv = np.array([1,parameters[0]]) # Line Vector\n",
    "    lv_norm = np.sqrt(sum(lv**2))\n",
    "    #\n",
    "    vects = {}\n",
    "    for center in centroids:\n",
    "        u = np.array(center) - np.array([0,parameters[1]])  # Calculates the vector from the origin of the line to the centroid\n",
    "        proj = lv * np.dot(u,lv) / (lv_norm**2)  # Projects the centroid onto the line\n",
    "        vects[retrieve_point_in_mask(masks, center)] = np.sqrt(np.sum(proj**2))  # Calculates each centroid's distance to origin and associates it to its respective mask\n",
    "    # Sorts masks by distance\n",
    "    sorted_masks = dict(sorted(vects.items(), key=lambda item: item[1]))\n",
    "    return list(sorted_masks)\n",
    "\n",
    "\n",
    "# Converts HSV values to paint's standard\n",
    "def cvtHSV(hsv):\n",
    "    return [int(i) for i in [hsv[0]*2, 0.3922*hsv[1], 0.3922*hsv[2]]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69827137-87b0-4501-8129-0c10731e0b1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Code used for extracting and handling color classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d648ef29-9731-48d8-9ae9-00020f620832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the CSV files' color data to create color classes\n",
    "def extract_colors(directory):\n",
    "    classes = dict()\n",
    "    for file in os.listdir(directory):\n",
    "        if os.path.isfile(file):\n",
    "            ext = file.split('.')[-1]\n",
    "            name = \".\".join(file.split('.')[:-1])\n",
    "            if ext == \"csv\":\n",
    "                with open(file) as csv_file:\n",
    "                    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                    line_count = 0\n",
    "                    summ = np.array([0,0,0])\n",
    "                    for row in csv_reader:\n",
    "                        H = int(row[0])\n",
    "                        S = int(row[1])\n",
    "                        V = int(row[2])\n",
    "                        hsv = np.array([H,S,V])\n",
    "                        line_count += 1\n",
    "                        summ += hsv\n",
    "                \n",
    "                classes[name] = summ/line_count\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a8aa0-1db9-42c7-8fcd-c5a6f5c8434c",
   "metadata": {},
   "source": [
    "### Merged inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af9bb976-680d-4538-b4b5-334b62251eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"Tests\\\\WhatsApp Image 2023-10-01 at 22.48.41.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ee68f7-1edc-444c-940a-f123924d8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\Users\\jhony\\Documents\\Jhony\\Universidade\\UTFPR\\2023.2\\Oficinas\\resistor-wizard\\Backend\\Tests\\WhatsApp Image 2023-10-01 at 22.48.41.jpeg: 320x640 (no detections), 110.5ms\n",
      "Speed: 1.0ms preprocess, 110.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "# Runs crop detection model on file\n",
    "cropped_inf = cropResistor(file, conf=0.6)\n",
    "\n",
    "# Crops and saves original file to a temporary location\n",
    "if len(cropped_inf[0].boxes.data):\n",
    "    cropped = cropImage(cv.imread(file), cropped_inf[0].boxes.cpu().data[0])\n",
    "else:\n",
    "    cropped = cv.imread(file)\n",
    "Image.fromarray(cv.cvtColor(cropped, cv.COLOR_BGR2RGB)).save(tmp_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d723e1-d057-40ff-a583-d28366bb3692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\Users\\jhony\\Documents\\Jhony\\Universidade\\UTFPR\\2023.2\\Oficinas\\resistor-wizard\\Backend\\Tests\\WhatsApp Image 2023-10-01 at 22.48.41.jpeg: 320x640 3 Resistor-Color-Bandss, 110.1ms\n",
      "Speed: 2.0ms preprocess, 110.1ms inference, 6.2ms postprocess per image at shape (1, 3, 320, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Runs color bands segmentation model on cropped inference\n",
    "if len(cropped_inf[0].boxes.data):\n",
    "    colorbands_inf = findColorBands(tmp_crop, save=True, conf=0.6, iou=0.3)\n",
    "else:\n",
    "    colorbands_inf = findColorBands(file, save=True, conf=0.6, iou=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f6043-0874-4459-aa08-b0ba1c350f3b",
   "metadata": {},
   "source": [
    "### Finds the order of bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c260e5-88bc-43bd-9458-ec7917b18aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets masks objects from the inference\n",
    "masks = get_segmentation_masks(tmp_crop, colorbands_inf)\n",
    "\n",
    "# Sorts the masks by distance (it doesn't have a way to \n",
    "#    know in which direction to start, so by default it \n",
    "#    uses the leftmost (0,0) point as a beginning.\n",
    "ordered = order_masks(masks, colorbands_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d10dbb-db6e-4f0c-bd7a-8f2efefb19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBOX: tensor([151.1857,  45.5712, 198.3011, 154.7171]) \t\t HSV: [344, 41, 21]\n",
      "BBOX: tensor([209.0540,  56.7224, 267.7925, 166.1478]) \t\t HSV: [347, 70, 35]\n",
      "BBOX: tensor([279.7240,  60.0277, 333.6953, 189.9935]) \t\t HSV: [347, 66, 35]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ordered)):\n",
    "    print(f\"BBOX: {ordered[i].bbox[:4]} \\t\\t HSV: {cvtBGR2HSV(ordered[i].avgColor[0], paint=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb16a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf960fb-f30a-4c74-9eb0-9762f4465691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the color name from masks average color\n",
    "# Numbers on the side represent the number of samples used for each color's average\n",
    "#  Files used to sample: res2.png, res.png, crop.jpg\n",
    "COLOR_RANGES = {}\n",
    "def sample_color_names(mask):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149f065-d16e-4573-8b51-88d3e8feebc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae56dc-7c72-41dd-bbc4-3e1c903f0e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5217e0-6dad-4d27-b043-77e48ae2989e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a7123-8d94-49bf-af6f-e4fc0c752f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4f1d9-e676-475f-a630-f1d75e45e969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

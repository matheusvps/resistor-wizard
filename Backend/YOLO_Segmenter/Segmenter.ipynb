{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343da895-72a6-45df-b548-cc3c46f45d17",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "    YOLO v8-segmentation training \n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee0294-e7e2-4c88-9683-849b4746e380",
   "metadata": {},
   "source": [
    "> ### This notebook contains the required code to train the YOLO v8 segmentation model and run its inference on a set of files\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c5048-6c8e-4d43-a182-3b277b817d70",
   "metadata": {},
   "source": [
    "#### Imports used packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3fecbc-0d3d-4ea9-aa5b-4eb43050be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports needed\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf732c2-3750-450c-83fc-b4e3a0ba8617",
   "metadata": {},
   "source": [
    "#### Loads pre-trained YOLO v8-segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfc76c0-d7a0-4567-9c6c-f10c0aa012a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model \n",
    "# Checkpoint = v3 = \"D:\\\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\ResistorWizard\\\\Backend\\\\YOLO_Segmenter\\\\runs\\\\segment\\\\train\\\\weights\\\\best.pt\"\n",
    "# Checkpoint = v3 + v6 = \"D:\\\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\ResistorWizard\\\\Backend\\\\YOLO_Segmenter\\\\runs\\\\segment\\\\train2\\\\weights\\\\best.pt\"\n",
    "model = YOLO(\"D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\resistor-wizard\\\\Backend\\\\YOLO_Segmenter\\\\latest\\\\best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ed5f67-a30e-4a15-99b9-3ff74a0b1a8b",
   "metadata": {},
   "source": [
    "#### Trains the loaded model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d72a067-77d5-4d3d-8be2-040ef093e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with custom dataset\n",
    "# results = model.train(data=\"D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\ResistorWizard\\\\Backend\\\\YOLO_Segmenter\\\\Metal Film Leaded Resistor Color Bands v6\\\\data.yaml\", epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36e1df-fdd6-4f86-8185-d99a1a0da070",
   "metadata": {},
   "source": [
    "#### Runs inference on a set of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db23b9ad-7dea-473b-8e28-5d30b0185d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of all files in a given directory\n",
    "def get_files(dir):\n",
    "    tests = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            tests.append(os.path.join(dir,name))\n",
    "    return tests\n",
    "\n",
    "files = get_files(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cc5e5a06-9aba-42aa-bcc0-7ed09dac0499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Joule\\Documents\\Jhony\\Universidade\\UTFPR\\2023.2\\Oficinas\\resistor-wizard\\Backend\\Tests\\res2.png: 640x640 4 Resistor-Color-Bandss, 1 Resistor-Color-Bands-Start, 130.0ms\n",
      "Speed: 9.6ms preprocess, 130.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "path_test = \"D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\resistor-wizard\\\\Backend\\\\Tests\\\\res2.png\"\n",
    "pred = model(path_test, save=True, conf=0.6, show_labels=False, show_conf=False, save_conf=True, iou=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf52ed23-67f5-481e-a105-8ede930090fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([458.2142, 282.1049, 528.2455, 450.5578])\n"
     ]
    }
   ],
   "source": [
    "boxes = pred[0].boxes.cpu().data\n",
    "vertex = [v[:4] for v in boxes]\n",
    "print(vertex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8308449a-741e-4ac2-81ce-b28bed23f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8828, 0.8774, 0.8707, 0.8647, 0.8473], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(pred[0].boxes.conf)\n",
    "classes = pred[0].names\n",
    "results_with_probs = [(result, classes[result.boxes.cpu().cls.numpy()[0]]) for result in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "78500dda-5595-4f85-a468-59003366c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if two colors are equal\n",
    "def eqq(a,b):\n",
    "    if len(a) != len(b):\n",
    "        return False\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class Mask:\n",
    "    def __init__(self, img, bbox=[], contour=[]):\n",
    "        self.image = img\n",
    "        self.orig_shape = img.shape\n",
    "        self.mask = np.zeros_like(img, dtype=np.uint8)  # creates mask of same size as original image\n",
    "        self.size = -1  # Number of non-zero pixels\n",
    "        self.avgColor = (None, None, None)\n",
    "        self.bbox = bbox\n",
    "        self.contour = contour\n",
    "        self.index = -1  # This color's position relative to others\n",
    "        self.color = \"\"  # A string identifier of the color the mask represents\n",
    "    #\n",
    "    def maskImage(self):\n",
    "        pixels = np.zeros_like(self.image, dtype=np.uint8)\n",
    "        for x in range(len(self.image)):\n",
    "            for y in range(len(self.image[0])):\n",
    "                if eqq(self.mask[x][y], [255,255,255]):\n",
    "                    pixels[x][y] = self.image[x][y]\n",
    "        return pixels\n",
    "    #\n",
    "    def sample_avg_color(self):\n",
    "        pixels = self.maskImage()\n",
    "        self.avgColor = np.sum(pixels.reshape((-1,1,3)), axis=0) / self.size\n",
    "        \n",
    "    # Checks if a point is inside the mask's bounding box\n",
    "    def contains(self, point):\n",
    "        if list(point) < self.bbox[0:2].tolist() or list(point) > self.bbox[2:4].tolist():\n",
    "            return False\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d6a24bc6-efbb-4c52-a52a-e406fd4674a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the centroid of a rectangle\n",
    "def get_centroid(vertex):\n",
    "    cX = (vertex[2] + vertex[0])/2\n",
    "    cY = (vertex[3] + vertex[1])/2\n",
    "    return (cX, cY)\n",
    "\n",
    "# Calculates the linear regression of the points in a 2D dataset: Y in function of X (Y= a*X + b)\n",
    "def lin_reg(data):\n",
    "    X = np.array([i[0] for i in data])\n",
    "    Y = np.array([i[1] for i in data])\n",
    "    a = ((len(data) * np.sum(X*Y)) - (np.sum(X) * np.sum(Y)))/(len(data) * np.sum(X*X) - (np.sum(X))**2)\n",
    "    b = ((np.sum(Y) * np.sum(X*X)) - (np.sum(X) * np.sum(X*Y)))/(len(data) * np.sum(X*X) - (np.sum(X))**2)\n",
    "    return a,b\n",
    "\n",
    "# Applies a linear equation on a point (Y = a*X + b)\n",
    "def f(x, params):\n",
    "    return params[0]*x + params[1]\n",
    "\n",
    "# Retrieves the pixels contained in the contours given by the model prediction\n",
    "def get_segmentation_masks(img, inference, data=255):\n",
    "    image = cv.imread(img)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "    masks = [Mask(image) for i in range(len(inference[0].masks.xy))]\n",
    "    #\n",
    "    for i in range(len(inference[0].masks.xy)):\n",
    "        polygon = inference[0].masks.xy[i].astype(int)\n",
    "        masks[i].bbox = inference[0].boxes.cpu().data[i]\n",
    "        masks[i].contour = polygon.reshape((-1, 1, 2))  # Reshape to match the format expected by cv.drawContours\n",
    "        masks[i].mask = cv.fillPoly(masks[i].mask, [masks[i].contour], (data, data, data)) # converts polygon points to pixels inside it\n",
    "        masks[i].size = 0\n",
    "        for j in masks[i].mask.reshape((-1,1,3)):\n",
    "            if not eqq(j[0], [0,0,0]):\n",
    "                masks[i].size += 1\n",
    "        masks[i].sample_avg_color()\n",
    "    return masks\n",
    "\n",
    "# Finds the mask that contains a given point – considers a point can belong to a single mask\n",
    "def retrieve_point_in_mask(masks, point):\n",
    "    for mask in masks:\n",
    "        if mask.contains(point):\n",
    "            return mask\n",
    "\n",
    "# Calculates the possible orders of the color bands – assumes the bands are approximately\n",
    "#     linear, which is reasonable given that resistors follow this standard\n",
    "def order_masks(masks, inference):\n",
    "    boxes = inference[0].boxes.cpu().data\n",
    "    vertex = [v[:4] for v in boxes]\n",
    "    centroids = [get_centroid(v) for v in vertex]\n",
    "    #\n",
    "    # Calculates the line that approximately crosses the centroids – it's used to find the order in which the bands are disposed\n",
    "    parameters = lin_reg(centroids)\n",
    "    lv = np.array([1,parameters[0]]) # Line Vector\n",
    "    lv_norm = np.sqrt(sum(lv**2))\n",
    "    #\n",
    "    vects = {}\n",
    "    for center in centroids:\n",
    "        u = np.array(center) - np.array([0,parameters[1]])  # Calculates the vector from the origin of the line to the centroid\n",
    "        proj = lv * np.dot(u,lv) / (lv_norm**2)  # Projects the centroid onto the line\n",
    "        vects[retrieve_point_in_mask(masks, center)] = np.sqrt(np.sum(proj**2))  # Calculates each centroid's distance to origin and associates it to its respective mask\n",
    "    # Sorts masks by distance\n",
    "    sorted_masks = dict(sorted(vects.items(), key=lambda item: item[1]))\n",
    "    return list(sorted_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "422e6823-78e6-4ee7-92cd-a88221fd4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the color name from masks average color\n",
    "# Numbers on the side represent the number of samples used for each color's average\n",
    "#  Files used to sample: res2.png, res.png, crop.jpg\n",
    "COLOR_RANGES = {  # ~ UPDATE this with better values after installing camera ~\n",
    "      \"BLACK\": (108, 115, 89),  # 2\n",
    "      \"BROWN\": (103, 95, 104),   # 4\n",
    "        \"RED\": (170, 173, 92),   # 2\n",
    "     \"ORANGE\": (16, 218, 164),   # 2\n",
    "     \"YELLOW\": (),\n",
    "      \"GREEN\": (57, 95, 169),    # 1\n",
    "       \"BLUE\": (),\n",
    "     \"VIOLET\": (116, 138, 172),  # 1\n",
    "       \"GREY\": (),\n",
    "      \"WHITE\": (),\n",
    "       \"GOLD\": (23, 72, 132),    # 2\n",
    "     \"SILVER\": (),\n",
    "}\n",
    "def sample_color_names(mask):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "06450307-2ee6-482e-a904-4da3061da8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = get_segmentation_masks(path_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "328bb0a4-13ea-49e3-9f9c-95b758e906bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Mask at 0x2ce8bd4f510>,\n",
       " <__main__.Mask at 0x2ceb39c5890>,\n",
       " <__main__.Mask at 0x2cdb177d3d0>,\n",
       " <__main__.Mask at 0x2ce8bd557d0>,\n",
       " <__main__.Mask at 0x2ce8bd54550>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ccb67711-6c9e-4583-8791-73cfbe57616f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "ordered = order_masks(masks, pred)\n",
    "print(len(ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4238bf53-c6f6-4dec-ad6b-383179f924ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBOX: tensor([163.2252, 347.4673, 237.1933, 539.1973]) \t\t HSV: [[     28.068      83.247      172.79]]\n",
      "BBOX: tensor([270.7560, 331.5136, 342.7377, 500.5215]) \t\t HSV: [[     17.103      106.41      103.37]]\n",
      "BBOX: tensor([351.3311, 351.6198, 427.5934, 478.7453]) \t\t HSV: [[     109.12      86.364      61.703]]\n",
      "BBOX: tensor([458.2142, 282.1049, 528.2455, 450.5578]) \t\t HSV: [[     14.965      214.58      173.12]]\n",
      "BBOX: tensor([537.4949, 244.9370, 608.6976, 440.3320]) \t\t HSV: [[     17.431      220.44       155.4]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ordered)):\n",
    "    print(f\"BBOX: {ordered[i].bbox[:4]} \\t\\t HSV: {ordered[i].avgColor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e9b625d-98cb-4d13-924b-030533216f7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(path_test)\n\u001b[1;32m----> 2\u001b[0m image_with_contours \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39maddWeighted(image, \u001b[38;5;241m1\u001b[39m, \u001b[43mm\u001b[49m[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Adjust opacity as needed\u001b[39;00m\n\u001b[0;32m      3\u001b[0m Image\u001b[38;5;241m.\u001b[39mfromarray(m[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mJoule\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mJhony\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUniversidade\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUTFPR\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m2023.2\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOficinas\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mresistor-wizard\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBackend\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mTests\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mres_contour.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "image = cv.imread(path_test)\n",
    "image_with_contours = cv.addWeighted(image, 1, m[0], 0.5, 0)  # Adjust opacity as needed\n",
    "Image.fromarray(m[0]).save(\"D:\\\\Joule\\\\Documents\\\\Jhony\\\\Universidade\\\\UTFPR\\\\2023.2\\\\Oficinas\\\\resistor-wizard\\\\Backend\\\\Tests\\\\res_contour.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1fefe-15a2-412e-a0a6-a9158f1b28f5",
   "metadata": {},
   "source": [
    "### Uses the trained model and a Convex Hull algorithm to auto-label new images for the dataset\n",
    "> #### Reduces workload and speeds up labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdb77e-f7a2-484d-927c-e89b2f28a037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
